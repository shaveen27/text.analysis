---
title: "Short Introduction to text.analysis Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Short Introduction to text.analysis Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(text.analysis)
set.seed(1234)
```

# Text Analysis Overview

Text analysis techniques such as Natural Language Processing (NLP) can swiftly 
extract relevant information from different corpus datasets such as documents, 
emails, SMS messages, social media and other textual resources. NLP encompasses 
some common techniques for analyzing human language such as tokenization, 
stemming and lemmatization, sentiment analysis and text classification.  

Working with text analysis using Natural Language Processing (NLP) involves 
several steps. Here's a general guide:

1. **Problem Definition:** Understand the objective of your text analysis. This 
could be to extract insights, classify text into categories, perform sentiment 
analysis, or something else.

2. **Data Collection:** Gather a corpus of text data relevant to your analysis. 
This could be from various sources such as websites, social media, books, 
articles, or any other text repositories.

3. **Data Preprocessing:** Implement data cleaning and normalization.
   
4. **Exploratory Data Analysis (EDA):** Understand the characteristics of your 
text data through statistical analysis, visualization, and summarization. This 
helps in identifying patterns and gaining insights.

5. **Model Selection:** Choose appropriate NLP models based on your problem and 
data characteristics. Common models include: Naive Bayes, Support Vector 
Machines, Random Forest, Logistic Regression.

6. **Model Training:** Split your data into training and testing sets. Train 
your chosen model(s) on the training data and tune hyperparameters to optimize 
performance.

7. **Model Evaluation:** Evaluate the performance of your trained model(s) using 
appropriate metrics for your task. For example, accuracy, precision, recall, 
F1-score, or Mean Squared Error (MSE) for regression tasks.


The **text.analysis** package provides an easy structure to follow those steps:

This document introduces you to the series of functions of the text.analysis 
package that allows a user to analyze a text dataset using some common Natural 
Language Processing techniques, train some models and evaluate their performance
. Once you have installed the package, read vignette(package = "text.analysis").


## Table of functions

**text.analysis** provides a series of functions for each step of the text 
analysis process. These functions can be organized into the following structure:

1. Load Data from text files

  + `read_maildf()` reads data file that contains email messages.
  + `convert_mail_list()` converts a data frame with  messages to `email_list` 
  object.

2. Explore the text dataset

  + `explore_data()` performs initial exploratory data analysis on text data.
  + `explore_visuals()` takes the results of the `explore_data` function and 
  creates visualizations.

3. Visualizing the corpus with word clouds

  + `wordcloud_all()` provides a visualization of the frequency of words in our 
  corpus.
  + `wordcloud_ham()` provides a visualization of the frequency of words in the 
  ham subset.
  + `wordcloud_spam()` provides a visualization of the frequency of words in the 
  spam subset.
  
4. Data Preprocessing: Standardization and cleaning  

  + `lower_case()` converts all messages to lower case.   
  + `remove_numbers()` removes numbers from messages.
  + `remove_punctuations()` removes punctuation from messages.  
  + `remove_whitespaces()` removes extra white spaces from messages.
  + `remove_stopwords()` removes stop words from messages.
  
5. Data partitioning: Creating training and testing datasets  

  + `partition()` creates training and testing data matrices.

6. Training a classifier on the data and evaluating model performance:  
  + `nb_classification()` computes accuracy measures for email data set using 
  Na√Øve Bayes classification model. 
  - Logistic Regression
  + `svm_classification()` computes accuracy measures for email data set using 
  Support Vector Machine classification model. 
  + `rf_classification()` computes accuracy measures for email data set using 
  Random Forest classification model. 
  + `log_classification()` computes accuracy measures for email data set using 
  logistic regression classification model. 
  
7. Comparing results: Evaluate the model performance and compare them  


## Data: SMSSpamCollection

To explore the text analyis process of this package, we will use the dataset 
`SMSSpamCollection`. The SMS Spam Collection is a public set of SMS labeled 
messages that have been collected for mobile phone spam research. 

```{r setup}
library(text.analysis)

data(SMSSpamCollection)

#see description of the dataset
?SMSSpamCollection
```

This dataset contains `r nrow(SMSSpamCollection)` observations and 
`r ncol(SMSSpamCollection)` columns.

```{r}
dim(SMSSpamCollection)

head(SMSSpamCollection)

```




